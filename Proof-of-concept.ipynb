{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dd3a35a",
   "metadata": {},
   "source": [
    "# Proof-of-concept: Company name mapping\n",
    "\n",
    "This jupyter notebook is used as a fully-documented proof-of-concept. \n",
    "Different concepts/approaches/solutions are tested, evaluated and documented.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0a30f",
   "metadata": {},
   "source": [
    "## 1. Presentation of the study case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3560c80",
   "metadata": {},
   "source": [
    "The case study is quite simple. A list of company names is provided. All these names were manually written. As a result, some of the names refer to the same entity but written differently. For instance, division names are written alongside the company name (i.e. ALTRAN INNOVACION for ALTRAN). Or the names can be written in non-standard way, with non-english characters or with common naming (i.e. 'INC.' or '& CO').The goal is to group the names from the same entity. \n",
    "\n",
    "As examples:\n",
    "- `ALTERYX` is equivalent to `ALTERYX, INC`\n",
    "- `ALTRAN INNOVACIÃƒÂ“N S.L.` is equivalent to `ALTRAN INNOVACION SOCIEDAD LIMITADA`\n",
    "- `AMICALE DES ANCIENS DU STADE` is different from `AMICALE JEAN BAPTISTE SALIS`\n",
    "\n",
    "An algorithm need then to be designed to efficiently map the names to their common entity, possibly written in a standardized way. Several answers can be given for a given name in order to let the user easily choose the proper entity name. \n",
    "\n",
    "The case study comes with a dataset of 5000 raw company names, but the algorithm is required to be scalable to larger datasets (e.g. 100,000 names). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896399e",
   "metadata": {},
   "source": [
    "## 2. Analyzing the problem\n",
    "\n",
    "This study case can be considered as a natural language processing (NLP) problem. Though, unlike a typical NLP problem, this one has the particularity of involving unsupervised machine learning techniques. There is no \"true\" answer given for each company name in the dataset, and therefore one has to find a way to clusterize the names based on a string metric that should quantify how likely two names are coming from the same entity. The choice of this string metric is therefore probably as important as the choice of the clusterization algorithm. Different metrics could be tested and can be chosen as function as the overall performance of the algorithm (efficiency and speed). \n",
    "\n",
    "One additional important step  of the algorithm will be the data pre-processing. The raw company names are given in a non-standard way, with many special characters like non-english characters, commas, dots, quotes, etc. A special care is then needed to clean the data and format them in a suitable  way for the clusterization algorithm. A possible step could be to remove to recurrent names that would not help the string metric (e.g. 'Inc.'). The list of these names could be found by finding the most recurrent sub-string in the dataset and by manually choose the ones that can be removed from the dataset. \n",
    "\n",
    "The output of the algorithm need to allow the user to choose himself the correct entity from a list of proposals. This feature will drive the choice of the clusterization algorithm. For instance, a hierarchical clustering will allow to organize the names into dendogram which would give the possibility of having several \"layers\" of clusterization.\n",
    "\n",
    "Evaluating the performance of the algorithm is required. Two metrics will have to be assessed: \n",
    " * The efficiency of the algorithm to properly map the name to the correct entity. Since we don't have the true answer, this will need to be manually evaluated. A possible way would be to choose N (e.g. 20) randomly-chosen names, define their true entity and check if it appears in the output of the algorithm. \n",
    " * The speed of the algorithm, and an estimation of the time to process a dataset of 100,000 names.\n",
    " \n",
    "After some research, I found a few solutions that were already proposed for similar problems:\n",
    " * [Company Names Standardization using a Fuzzy NLP Approach](https://rajanarya.com/2020/03/28/company-names-standardization-using-a-fuzzy-nlp-approach/) that identifies 'Stop-words' (common terms), removes them from the data, defines a pairwize similarity matrix bazed on a fuzzy matching of strings, clusterizes the names based on this matrix using the Affinity clustering technique and find the most commonly occuring longest common string for each cluster. \n",
    " * [Supplier Name Standardization using Unsupervised Learning](https://medium.com/analytics-vidhya/supplier-name-standardization-using-unsupervised-learning-adb27bed9e0d) that use basically the same approach as above.\n",
    " \n",
    "While these solutions are inspiring, it is not clear if they are fast enough to be used for a large number of names. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449e620",
   "metadata": {},
   "source": [
    "## 3. Pre-processing the data\n",
    "\n",
    "Importing the necessary librairies first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3bd867cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd6aaf",
   "metadata": {},
   "source": [
    "Extract the raw name dataset as a pandas serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "de8cd945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          \"ACCESOS NORMALIZADOS, SL\"\n",
       "1       \"ALTAIX ELECTRONICA , S.A.L.\"\n",
       "2      \"ANTALA LOCKS & ACCESORIS, SL\"\n",
       "3                       \"ANTERAL, SL\"\n",
       "4        \"ARQUIMEA INGENIERIA , S.L.\"\n",
       "5    A & D ENVIRONMENTAL SERVICES LTD\n",
       "6                      A & L GOODBODY\n",
       "7                      A & P - LITHOS\n",
       "8    A & T STATIONERS PRIVATE LIMITED\n",
       "9              A A LOGISTIK-EQUIPMENT\n",
       "Name: Raw name, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_excel(\"Case_study_names_mapping.xlsx\", usecols=[0])\n",
    "data = dfs['Raw name']\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e6aa1c",
   "metadata": {},
   "source": [
    "Some encoding issues can already found for some of the names: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "94359327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AHP Gesellschaft fÃ\\x83Â¼r Informationsverarbeitung mbH'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1255]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885fe131",
   "metadata": {},
   "source": [
    "This is probably coming from non-english characters. The data is then uniformized and encoded into utf-8: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "51969fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AHP Gesellschaft fAA14r Informationsverarbeitung mbH'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data.str.normalize('NFKD').str.encode(\"ascii\",'ignore').str.decode(\"utf-8\",\"ignore\")\n",
    "data_clean.iloc[1255]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed266e8",
   "metadata": {},
   "source": [
    "This preserves the presence of unrecognized characters. This is not perfect, but it will do the job for now.\n",
    "\n",
    "The characters are then lowered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4d2a574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ahp gesellschaft faa14r informationsverarbeitung mbh'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data_clean.str.lower()\n",
    "data_clean.iloc[1255]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036409e",
   "metadata": {},
   "source": [
    "Next, the special characters are removed. The list of ponctuation characters are extracted from `string`. The ampersand symbol (i.e. `&`) is removed from this list as this is a common character used for company names (e.g. AT&T) which can be a useful information for the clustering algorithm.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "02bec714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             accesos normalizados sl\n",
       "1              altaix electronica sal\n",
       "2         antala locks & accesoris sl\n",
       "3                          anteral sl\n",
       "4              arquimea ingenieria sl\n",
       "5    a & d environmental services ltd\n",
       "6                      a & l goodbody\n",
       "7                        a & p lithos\n",
       "8    a & t stationers private limited\n",
       "9               a a logistikequipment\n",
       "Name: Raw name, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation_custom = string.punctuation.replace('&','') # !\"#$%'()*+,-./:;<=>?@[\\]^_`{|}~\n",
    "data_clean = data_clean.apply(lambda x: re.sub('[%s]'%re.escape(punctuation_custom), '' , x)) ## ponctuation\n",
    "data_clean = data_clean.apply(lambda x: re.sub('  ', ' ' , x)) ## double space\n",
    "data_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa68180",
   "metadata": {},
   "source": [
    "To find the stop-words in the raw names, the most frequent words are first listed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3ee13c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Word  Frequency\n",
      "0           gmbh        798\n",
      "1              &        263\n",
      "2            ltd        234\n",
      "3             de        162\n",
      "4             co        140\n",
      "5            inc        131\n",
      "6    association        126\n",
      "7             sl        123\n",
      "8             kg        114\n",
      "9             sa        113\n",
      "10           sas         95\n",
      "11      autohaus         93\n",
      "12      services         84\n",
      "13       limited         80\n",
      "14         group         71\n",
      "15        france         66\n",
      "16             a         61\n",
      "17  technologies         59\n",
      "18           und         57\n",
      "19       systems         57\n",
      "20     solutions         56\n",
      "21    consulting         55\n",
      "22           llc         49\n",
      "23      advanced         45\n",
      "24          sarl         44\n"
     ]
    }
   ],
   "source": [
    "words = data_clean.str.cat(sep=' ').split()\n",
    "word_dist = nltk.FreqDist(words)\n",
    "\n",
    "rslt = pd.DataFrame(word_dist.most_common(25),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "print(rslt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff9e55",
   "metadata": {},
   "source": [
    "The stop-words are then manually chosen by checking all the cells that contains these words. E.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "62a9ce72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52                 a&e logistik gmbh & co kg\n",
       "74                    as frucht gmbh & co kg\n",
       "296            absolut karriere gmbh & co kg\n",
       "303                       abtec gmbh & co kg\n",
       "357                     accemic gmbh & co kg\n",
       "512                        acsg gmbh & co kg\n",
       "568                  active blue gmbh & cokg\n",
       "569                  active blue gmbh & cokg\n",
       "621           adalbert zajadacz gmbh & co kg\n",
       "624     adam keller baugeschaft gmbh & co kg\n",
       "625    adam keller baugeschaeft gmbh & co kg\n",
       "627               adams consult gmbh & co kg\n",
       "645                         adc gmbh & co kg\n",
       "720               adex beratungs gmbh & cokg\n",
       "789                    adolf lupp gmbh co kg\n",
       "790               adolf mueller gmbh & co kg\n",
       "792                    adolf reiss & sohn kg\n",
       "794                 adolf warth gmbh & co kg\n",
       "796                  adolf wrth gmbh & co kg\n",
       "797                adolf wuerth gmbh & co kg\n",
       "Name: Raw name, dtype: object"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[data_clean.str.contains(\"kg\")].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4fad0d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             accesos normalizados\n",
       "1           altaix electronica sal\n",
       "2         antala locks & accesoris\n",
       "3                          anteral\n",
       "4              arquimea ingenieria\n",
       "5     a & d environmental services\n",
       "6                   a & l goodbody\n",
       "7                     a & p lithos\n",
       "8         a & t stationers private\n",
       "9            a a logistikequipment\n",
       "10                a a z consulting\n",
       "11                a and m portable\n",
       "12                      a arnegger\n",
       "13                 a b fluid power\n",
       "14                a bis z allround\n",
       "15                     a e petsche\n",
       "16                  a e petsche uk\n",
       "17                   a et p lithos\n",
       "18              a foubert visserie\n",
       "19                   a joy wallace\n",
       "Name: Raw name, dtype: object"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = [\"gmbh\", \"& co\", \"co\", \"kg\", \"cokg\", \"ltd\", \"limited\", \"sl\", \"inc\", \"sa\", \"sarl\", \"sas\", \"llc\", \"dba\"]\n",
    "data_clean = data_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "data_clean.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fbba04",
   "metadata": {},
   "source": [
    "The country names (e.g. `france`) could possibly be removed, but some of the entity names contain the country (e.g. `AGENCE FRANCE-PRESSE`). \n",
    "\n",
    "In the future, some tests could be done by using a more aggressive stop-words cleaning (e.g. removing other common words such as `technologies`, `services`, `systems`, `solutions`, `consulting`, etc). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc2013",
   "metadata": {},
   "source": [
    "## 4. Finding the good name-similarity metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df52fa",
   "metadata": {},
   "source": [
    "## 5. Clustering the names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87d32f",
   "metadata": {},
   "source": [
    "## 6. Presenting the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d802d",
   "metadata": {},
   "source": [
    "## 7. Evaluating the performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
